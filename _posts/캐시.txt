자, 이제 이번 시간에는 잠시 컴퓨터 구조 원리에 대한 내용에 대해서 좀 알아보고자 하는데요 특히나 이제 캐시랑 파이프라인 위주로 알아볼 겁니다 왜 뜬금없이 갑자기 이제 와서 이런 이론적인 컴퓨터 구조에 대한 내용을 다루냐면요 , 사실, 다음 시간에 배울 메모리 모델이랑 얘가 좀 밀접한 관련이 있습니다 그래가지고 지금 당장 필요해 가지고 이제 이거를 알아보는 거고요 , 일단은, 캐시부터 시작을 할 건데 캐시라는 용어에 대해서 들어보셨는지 모르겠지만 , 일단은, 왜 캐시가 필요한지 한번 알아보자면요 우리가 컴퓨터의 두뇌에 해당하고 실질적인 연산을 해주는 애를 CPU라고 하죠 그리고 , 사실, 여러분들이 컴퓨터 조립을 직접 해보셨는지 모르겠지만 한 번쯤은 해보면 굉장히 많은 도움이 됩니다. 그래서 컴퓨터를 뜯어가지고 조립을 할 때 보시면은 지금 , 이렇게, 빨간색 영역으로 , 이렇게, 표현을 한 게 얘가 CPU 부품입니다. 그래서 뚜껑을 뜯어가지고 열어서 보면 CPU가 여기 장착이 되어 있을 거고요. 그 다음에 여기 , 이렇게, 4개로 꽂혀있는 이 스틱같이 생긴 애들이 이제 램 부품을 얘기하고 있는 거예요. CPU 램 뭐 굉장히 단순하죠? 근데 여기서만 딱 봐도 뭔가 하나 위화감을 느낄 수 있는 게 결국에는 CPU는 연산을 해주는 아이고 램은 실질적으로 메모리에 해당하는 애죠. 그러니까 CPU가 사용하는 그러니까 나중에 연산을 해야 되는 그런 데이터를 우리가 램에다가 올려 가지고 다 사용을 하게 될 건데 여기 데이터가 저장된 거를 연산을 하기 위해서 , 이렇게, 꺼내 가지고 얘가 이제 활용하게 될 겁니다. 그러니까 우리가 소위 말하는 뭐 스택 메모리니 힙 메모리니 하는 것들이 결국에는 여기 램 어딘가에 지금 올라와 있는 상태라고 보시면 되겠어요. 그런데 그때마다 뭔가 접근을 해가지고 사용할 때마다 요 먼거리를 왔다갔다 이동을 하면은 이게 은근히 쓸데없는 그런 시간 낭비를 하게 되겠죠 , 사실, CPU는 굉장히 굉장히 빨라가지고 빠르게 동작을 하는데 CPU만 고지곳대로 혼자 동작하는 경우는 생각보다 많이 없고 보통 대부분 저기 멀리 있는 어떤 유저나 몬스터의 데이터를 꺼내가지고 그 데이터를 기반으로 우리가 연선을 하는 경우가 많죠 그러니까 CPU 하나 연선을 하는 시간에 한 40번, 50번을 연산하는 시간에 데이터를 한 번만 , 이렇게, 사실, 꺼내가지고 사용할 수 있기 때문에 이 데이터 전송하는 비용이 이 CPU 연산 비용에 비해서 진짜 어마무시하게 큽니다. 그러니까 당연히 고지곳대로 매번마다 데이터가 필요하거나 할 때마다 여기 메모리, 램에 접근해가지고 데이터를 꺼내 쓰는 거는 올바른 방법이 아니라는 거죠. 그래가지고 이걸 이제 어떻게 오해를 했냐면은 컴퓨터 설계자들이 어떻게 오해를 했냐면은 캐시라는 거를 도입을 하기 시작을 했습니다. 캐쉬는 말 그대로 임시 저장소 같은 개념이라고 보시면 되겠어요 그래가지고 뭐 연구적으로 유지되고 뭐 그런 개념은 아니고요 일종의 그냥 메모장이라고 생각을 하시면 되겠습니다 그래서 실질적으로 어 우리가 CPU를 뜯어서 보면은 ALU라고 해가지고 실질적으로 뭐 더샘, 뺄샘, 곱샘 같은 그런 연산을 해주는 장치가 있을 것이고 그 바로 근처에 뭔가 임시적으로 저장할 수 있는 캐시 메모리가 , 이렇게, 같이 들어가 있을 겁니다 세트로 근데 심지어 캐시가 딱 하나만 있는 것도 아니고 단계별로 여러 가지를 , 이렇게, 두고 있어요 레지스터도 있을 것이고 L1 캐시, L2 캐시, L3 캐시 이런 식으로 피라미드 구조로 되어 있는데요 여기서 피라미드 구조에서 , 이렇게, 위로 갈수록 귀족인 거죠 얘는 굉장히 용량이 작은 대신 정말로 ALU 바로 옆에 있어 가지고 코어 옆에 있어 가지고 아주 가깝게 빠르게 접근할 수 있는 애고요 내려가면 내려갈수록 점점점점 용량은 커지지만 당연히 접근하는 비용도 커지게 되겠습니다 그래서 점점점점점 조금씩 효율이 떨어지는 그런 캐시가 되는 거고 여기까지 , 일단은, 캐시를 뒤졌는데도 없으면은 그제서야 이제 원래 있던 저 램까지 가가지고 데이터를 꺼내 온다고 보시면 되겠어요 이런 느낌으로 동작을 하게 됩니다 그래서 실질적으로 우리가 어떤 데이터를 램에서 꺼내 올 때 그거를 다음에 혹시라도 또 필요하게 될 수도 있으니까 , 일단은, 여기 어딘가에 캐시에 , 일단은, 저장을 해두게 됩니다 그래서 동일한 데이터 혹은 인접한 데이터를 만약에 우리가 또 필요해서 사용을 한다고 가정을 했을 때 CPU가 그걸 무조건 램에 가서 찾는 게 아니라 , 일단은, 자기가 들고 있는 이 캐시 메모리 중에서 그 해당 주소의 값을 들고 있는지를 먼저 체크를 해본 다음에 내가 이미 알고 있는 값이라고 하면 램까지 가지 않고 , 이렇게, 캐시에 있는 데이터를 꺼내가지고 여기 대상으로 조작을 한다는 얘기가 되는 거죠. 물론 여기 캐시 용량 자체가 크지는 않기 때문에 이제 점점점점 프로그램이 진행이 될수록 용량이 꽉 차가지고 더 이상 저장할 수 없다고 하면은 당연히 제일 오래되고 제일 사용 빈도가 떨어지는 데는 이제 폐기를 하고 새로운 데이터로 덮어쓰고 하는 식으로 이제 동작을 하게 될 겁니다. 그래서 , 이렇게, 캐시라는 중간 저장소가 있다는 걸 반드시 기억하셔야 되는 거고요 실질적으로 인텔 칩 같은 걸 까봐서 이 공식 문서를 가보면 지금 , 이렇게, CPU가 코어가 여러 개가 있는데 거기에 마다 이런 식으로 L1 캐시, L2 캐시, L3 캐시와 같은 임시 저장소가 , 이렇게, 각각 배치되어 있는 걸 볼 수가 있습니다 얘는 용량이 조금 더 작지만 정말로 , 이렇게, 코어 옆에 붙어있고 얘는 용량이 좀 더 크지만 조금 거리가 멀어져 있다는 걸 알 수가 있는 거죠 이런 식으로 점점점점 멀어지다가 여기까지 체크해서 없으면 그제서야 이제 램까지 가는 그런 상황이라고 볼 수가 있겠습니다 그래서 캐시를 이제 설계를 할 때 여러가지를 고려해야 되겠지만 가장 기본적으로 , 이렇게, 두가지 템포럴 로컬리티랑 스페셜 로컬리티 두가지를 일단 가장 먼저 고려를 합니다 그게 뭐냐면은 시간적으로 봤을 때 이미 우리가 접근한 데이터를 가장 최근에 접근한 데이터를 또 사용할 빈도가 높을 것이다라는 가정을 하고 설계를 할 것이고요. 말 그대로 시간적으로 생각했을 때 2시간 전에 주문한 테이블보다 방금 주문한 테이블에서 뭔가 또 추가 주문이 나올 것 같은 그런 예감이 든다는 그런 철학을 갖고 있는 거죠. 그리고 공간적으로 봤을 때 방금 주문한 사람 바로 옆에 있는 사람이 또 추가 주문을 할 확률이 높다고 생각하는 겁니다 예를 들면 이게 어떤 상황이냐면은 우리가 뭐 4문을 만약에 돈다고 가정해볼게요 4문을 돈다고 했을 때 보통 이제 아이를 0번부터 아이를 1000번씩 계속 스캔을 하면서 어떤 배열을 우리가 술자적으로 막 , 이렇게, 접근을 한다고 가정해봅시다 그러면은 그 배열을 순차적으로 접근한다는 것 자체가 메모리 기준으로 보면은 어떤 특정 주소에 접근을 한 다음에 바로 그 인접한 다음 주소에 접근하고 다음 주소에 접근하고 이런 식으로 계속 이어가지고 접근할 확률이 굉장히 높다는 얘기가 되는 거죠 뭐 그런 걸 고려해가지고 결국 가장 최근에 그리고 이미 접근한 데이터 바로 옆에 있는 데이터를 또 접근할 확률이 높다라는 걸 기반으로 이제 캐시를 설계해가지고 이제 작동을 하게 될 거예요 근데 물론 우리가 캐시를 직접적으로 뭐 사용하기는 하지만 직접적으로 우리가 이걸 건드릴리는 당연히 없습니다 하지만 이 존재에 대해서는 어렴풋이나마 알아야 된다는 얘기가 되는 거고 진짜로 여러분들 컴퓨터에서도 이 캐시가 존재하는지 의심스러우니까 일단 가벼운 실습을 하나를 하고 돌아오도록 하겠습니다 , 자, 이렇게, 다시 Visual Studio 로 , 일단은, 돌아왔구요 오늘 할 실습은 굉장히 단순한 겁니다 , 일단은, Windows 헤더가 추가가 되었는지 , 일단은, 체크를 해주시구요 2차 배열을 , 이렇게, 전역으로 하나를 만들어 주도록 할게요 만개의 만개짜리의 이런 2차원 배열입니다 뭐 , 일단은, 쓰레기값이 들어있을 수 있으니까 맵셋을 통해 가지고 , 일단은, 요런 식으로 0으로 다 밀어 주도록 할 거구요 뭐 , 사실, 이건 큰 의미 없어요 그냥 해보는 겁니다 , 자, 그 다음이 중요한데 이제 이거를 뺑뺑이 루프를 돌면서 , 사실, 어떤 값을 우리가 넣어주지 않았으니까 딱히 뭐 어떤 값을 바라고 하는 건 아니지만 각기 접근하는 그런 테스트를 해보게 될 겁니다 근데 접근 순서가 살짝 달라지게 될 건데 처음에는 이런식으로 만번에 대해서 , 이렇게, 하나씩 하나씩 접근을 할 것이고 j도 만번을 , 이렇게, 접근을 할 것인데요 여기서 중요한건 뭐냐면 첫번째 경우에는 i,j 순서로 , 이렇게, 접근을 해주게 될겁니다 어 그래가지고 요기서 이제 그 다음에 볼거는 얘가 얼마의 시간이 걸렸는지를 일단 틱을 개선해가지고 한번 출력을 해보도록 할게요 스타트 틱 겟 틱 카운트 64 라고 해가지고 프로그램이 실행된 이후에 틱을 뭔가 , 이렇게, 나타내는데 얘가 지금 당장 어떤 값이 중요한건 아니지만 스타트랑 엔드를 찍어가지고 요 차이를 차이를 출력을 해가지고 얘가 어느정도 걸렸는지 시간을 지금 측정하고 있는 상황이라고 보시면 되겠어요 그래가지고 elapsed tick 몇초의 tick이 경고했습니다 라는거를 , 이렇게, end minus start를 log로 , 이렇게, 찍어 보도록 할게요 그 다음에 이걸 이제 한번만 더 해주게 될건데 이제 하나 달라지는거는 요 순서를 J랑 I로 , 이렇게, 일단은, 바꿔치기를 해주도록 하겠습니다 그럼 이제 이거를 실행해 봤을 때 둘의 시간 차이가 얼마 정도 날지가 굉장히 궁금한데 만약에 컴퓨터 구조 원리 같은 거를 다 무시하고 그냥 순전히 적은 횟수만 보면은 , 사실, 이렇게, 하나, 이렇게, 하나 뭐 똑같죠? 1만 x 1만이니까 달라질 이유가 하등 없습니다 하지만 실질적으로 얘를 지금 디버그 상태에서 , 이렇게, 한번 실행을 해보면 , 자, 이게 의외로 거의 3배, 4배 정도 차이 난다는 걸 테스트를 해볼 수가 있어요. 즉, 첫 번째 방법. 이 위에서 사용하는 이 방법이 훨씬 더 빠르게 동작하는 얘기가 되는 거죠. 어, 나는 지금까지 코드를 짜면서 이런 부분을 생각해 본 적이 없는데 굉장히 놀랄 수도 있지만 이런 게 이제 은근슬쩍 숨겨져 있는 그런 캐시가 동작하는, 열일을 하는 그런 상황이라고 보시면 되겠습니다. 그러면 왜 이 첫 번째 상황이 두 번째 상황보다 더 잘 동작하는지를 생각을 해보면 되는데 이 버퍼라는 메모리 자체가 우리가 2차원 배열로 만들기는 했지만 2차원 배열이라는 게 사실상 , 이렇게, 1차원 배열이랑 별로 다를 바가 없죠 근데 그게 이제 , 이렇게, 연속해가지고 이런 식으로 여러 개가 있는 거를 우리가 2차원 배열이라고 하고 있는 겁니다 근데 좀 구분하기 쉽게 , 이렇게, 좀 띄워놓도록 할게요 , 사실, 얘네 둘은 붙어있는 상황이죠 , 자, 이 상황에서 우리가 첫번째 방법을 이용해가지고 , 이렇게, 쭉 스캔을 할 때는 여기 있는 j가 바뀌고 j가 먼저 바뀐 다음에 그 다음에 j가 끝났으면 그 다음에 i가 1 늘어나는 상황으로 , 이렇게, 동작을 하고 있어요. 실질적으로 메모리를 보면 여기서 시작을 한 다음에 j가 하나씩 증가한다는 것은 여기서 다음 데이터, 그 다음 데이터, 그 다음 데이터, 그 다음 데이터, 그 다음 데이터 이런 식으로 이 순서대로 그냥 쭉 스캔을 돌면서 지금 , 이렇게, 데이터를 꺼내 쓰고 있는 상황이라고 볼 수가 있겠습니다. 그런데 아까 얘기한 대로 , 사실, 우리가 캐시라는 거를 이제 컴퓨터가 사용을 할 때 실질적으로 램에서 만약에 우리가 하나의 정수만 필요한 상황이라고 과정해볼게요. 그러니까 사실상 얘가 인트32니까 이 00에 해당하는 요 정보를 만약에 우리가 램에서 추출을 해온다고 과정했을 때 정말로 고지곳대로 그 데이터만 꺼내오는 건 아닙니다. 왜냐하면 아까 얘기한 캐시 철학에서 그 Special Locality라고 해가지고 인접한 데이터가 곧 활용이 될 가능성이 높다라는 철학으로 얘가 만들어져 있기 때문에 실질적으로 얘만 달랑 갖고 오는 게 아니라 인접한 블록 단위로 꽤 많은 데이터들을 긁어와서 , 일단은, 그거를 캐시에다가 저장을 해주게 돼요 그렇기 때문에 그 상황에서 바로 그 다음 데이터를 찾아오는데 이제 이 데이터가 과연 캐시에 있습니까라는 질문을 했을 때 운 좋게 바로 이전 데이터 옆에 있는 데이터였기 때문에 이 블록이 지금 캐시 저장이 되어있기 때문에 얘는 이미 캐시 들어가 있는 데이터가 돼요 이런 상황 우리가 캐시 히트라고 합니다 캐시 명중 오케이 그러면 이 경우에는 굳이 램까지 멀리 가지 않더라도 캐시는 데이터를 그대로 사용할 수 있기 때문에 캐시 히트 캐시 히트 캐시 히트 캐시 히트 연속해서 , 이렇게, 일어나기 때문에 굉장히 빠르게 동작하는 상황이라고 볼 수 있는 거죠 하지만 반대로 요 상황은 지금 어떤 상황이냐면은 , 자, 요기 이 i가 어 요렇게 지금 j가 먼저 얘가 먼저 , 이렇게, 늘어나고 있죠 지금 요 상황입니다 j가 먼저 늘어나고 그 다음에 j가 한바퀴 돈 다음에서야 i가 1 증가하는 상황인데 얘는 어떤 상황이냐면은 우선 요기 있는 데이터를 00에 해당하는 데이터를 먼저 꺼내왔습니다 여기까진 똑같죠 , 자, 그런데 뭐 역시나 이 인트32짜리 하나만 사용한다고 해가지고 걔만 고지곳대로 꺼내오는 건 아니고 아까 얘기한 스페셜 로칼리티 때문에 인접한 데이터에 해당하는 요 블록 단위를 어느 정도 같이 꺼내와 가지고 , 일단은, 캐시에 저장을 하게 돼요 하지만 굉장히 불안하게도 얘가 이제 하는 행동을 보면은 바로 옆에 있는 데이터를 꺼내 쓰는 게 아니라 제일을 먼저 늘리고 있습니다 다음 블록으로 뿅! , 이렇게, 순간이동을 해가지고 접근하기 때문에 사실상 얘를 한 다음에 그 다음에 얘로 하고 그 다음에 얘로 이동하고 그 다음에 얘로 이동하고 이걸 딱 끝난 다음에서야 다시 얘로 돌아와가지고 그 다음 데이터 , 이렇게, 이렇게, 하나씩 지금 스캔을 하고 있는 거예요. 그러다보니까 굉장히 띄엄띄엄띄엄 접근을 하고 있기 때문에 기껏 옆에 있는 데이터가 사용이 될 거라고 굉장히 기대하면서 얘를 캐시에다가 긁어왔지만 실제로 우리가 절묘하게 이 캐시에 지금 저장된 걸 피해 다니면서 엉뚱하게 멀리 있는 데이터를 계속 꺼내 쓰고 있는 상황이 되는 거죠. 그렇기 때문에 물론 그렇다고 해서 아예 캐시가 0% 확률로 지금 적중을 안 하는 건 아닐 테고 당연히 캐시도 용량이 어느 정도 있으니까 어느 정도는 히트 나겠지만 , 이렇게, 확실히 연속해서 짜르르르 접근할 때보다는 당연히 명중률이 떨어질 수밖에 없기 때문에 명중률이 떨어진다는 것은 결국에는 램까지 돌아가서 그 데이터를 꺼내오는 상황이 된다고 보시면 되겠습니다 그렇기 때문에 이 두 번째 방법이 첫 번째 방법보다 느리게 동작한다고 , 일단은, 결론을 내릴 수가 있는 거고 , 이렇게, 해가지고 이 실습을 통해 가지고 여러분도 똑같이 두 번째 상황이 더 느리게 동작했다고 된다고 하면 역시나 여러분 컴퓨터에서도 캐시가 잘 동작하고 있다고 결론을 내릴 수가 있겠습니다 , 이렇게, 해가지고 간단하게 , 일단은, 캐시 실습을 마치도록 할게요.